{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from bokeh.io import output_file\n",
    "import bokeh.plotting as bk\n",
    "from bokeh.plotting import figure, show, output_file,curdoc\n",
    "from bokeh.models import HoverTool, ColumnDataSource,CustomJS,Select,PreText,LinearColorMapper,BasicTicker,ColorBar,Div\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn,Dropdown\n",
    "from bokeh.layouts import row,column,gridplot\n",
    "from bokeh.palettes import Category10,Category20,cividis,inferno,viridis\n",
    "\n",
    "from math import pi\n",
    "\n",
    "#bk.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('X_test.csv')\n",
    "tfidf = pd.read_csv('tfidf.csv')\n",
    "COLUMNS = ['text','tokens','airline_sentiment','predictions','negative','neutral','positive']\n",
    "data = data[COLUMNS]\n",
    "source = ColumnDataSource(dict(data))\n",
    "CATEGORY_DICT = {0:'negative',1:'neutral',2:'positive'}\n",
    "CLASS_NAME = ['negative','neutral','positive']\n",
    "N_CLASS=3\n",
    "ACTUAL_LABEL='airline_sentiment'\n",
    "PREDICTED_LABEL = 'predictions'\n",
    "N_TOP=15\n",
    "COLOR_CODE_LIST = Category20[N_TOP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = Div(text='<h1 style=\"text-align: center\">US Airlines Sentiment Analysis ML Model Report</h1>')\n",
    "#show(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFUSION_MATRIX = confusion_matrix(data[ACTUAL_LABEL],data[PREDICTED_LABEL])\n",
    "NORMALIZED_CONFUSION_MATRIX=CONFUSION_MATRIX.astype('float')*100 / CONFUSION_MATRIX.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Heatmap\n",
    "x_axis_list = []\n",
    "y_axis_list = []\n",
    "total_count = []\n",
    "for i_row in range(N_CLASS):\n",
    "    for j_col in range(N_CLASS):\n",
    "        x_axis_list.append(CATEGORY_DICT[i_row])\n",
    "        y_axis_list.append(CATEGORY_DICT[j_col])\n",
    "        total_count.append(NORMALIZED_CONFUSION_MATRIX[i_row][j_col])\n",
    "heatmap_source = pd.DataFrame(list(zip(x_axis_list,y_axis_list,total_count)),columns=['ActualLabel','PredictedLabel','TotalCount'])\n",
    "heatmap_source = ColumnDataSource(dict(heatmap_source))\n",
    "\n",
    "correct_y_range = sorted(list(set(x_axis_list)), reverse=True)\n",
    "correct_x_range = sorted(list(set(y_axis_list)))\n",
    "\n",
    "\n",
    "colors = ['#00007F', '#0000ff', '#007FFF', '#00ffff', '#7FFF7F', '#ffff00', '#FF7F00', '#ff0000', '#7F0000']\n",
    "colors = viridis(9)\n",
    "mapper = LinearColorMapper(palette=colors, low=heatmap_source.data['TotalCount'].min()-1, high=heatmap_source.data['TotalCount'].max()+1)\n",
    "\n",
    "\n",
    "\n",
    "heatmap = figure(title=\"Confusion Matrix\",\n",
    "     x_axis_location=\"above\", tools=\"save\",plot_width=400,plot_height=300,\n",
    "    tooltips=[('Actual', '@ActualLabel'), ('Predicted', '@PredictedLabel'), ('Total(%)', '@TotalCount')],\n",
    "     y_range=correct_y_range, x_range=correct_x_range)\n",
    "\n",
    "heatmap.x_range.range_padding = 0\n",
    "heatmap.y_range.range_padding = 0\n",
    "#heatmap.xaxis.ticker = x_axis_list\n",
    "#heatmap.yaxis.ticker = y_axis_list\n",
    "heatmap.grid.grid_line_color = None\n",
    "heatmap.axis.axis_line_color = None\n",
    "heatmap.axis.major_tick_line_color = None\n",
    "#heatmap.axis.major_label_text_font_size = \"5pt\"\n",
    "#heatmap.axis.major_label_standoff = 0\n",
    "#heatmap.xaxis.major_label_orientation = pi / 3\n",
    "\n",
    "#heatmap.plot_width = 600\n",
    "#heatmap.plot_height = heatmap.plot_width\n",
    "\n",
    "rectwidth = 0.9\n",
    "\n",
    "#heatmap = figure(title='Confusion Matrics',x_axis_location=\"below\")\n",
    "heatmap.rect(\"PredictedLabel\",\"ActualLabel\",  rectwidth, rectwidth,#  here width is set to an adequate level. \n",
    "       source=heatmap_source,\n",
    "       fill_color={'field': 'TotalCount', 'transform': mapper},\n",
    "       line_color=None)\n",
    "\n",
    "color_bar = ColorBar(color_mapper=mapper, major_label_text_font_size=\"5pt\",\n",
    "                     ticker=BasicTicker(desired_num_ticks=len(colors)),\n",
    "                     label_standoff=6, border_line_color=None, location=(0, 0))\n",
    "\n",
    "heatmap.add_layout(color_bar,'right')\n",
    "#show(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dropdown_options(n_class,category_dict,confusionMatrix):\n",
    "    options=[]\n",
    "    for i in range(n_class):\n",
    "        for j in range(n_class):\n",
    "            option = 'Actual : '+category_dict[i]+'  Predicted : '+category_dict[j] + '  Total : '+str(confusionMatrix[i,j])\n",
    "            options.append(option)\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPDOWN_OPTIONS = get_dropdown_options(N_CLASS,CATEGORY_DICT,CONFUSION_MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### # set up widgets\n",
    "Classification_Report = classification_report(data[ACTUAL_LABEL],data[PREDICTED_LABEL])\n",
    "classification_report = PreText(text=Classification_Report, width=500)\n",
    "\n",
    "classification_report_summary = PreText(text='Classification Report', width=500)\n",
    "#confusion_matrix = PreText(text=Confusion_Matrix, width=500)\n",
    "dropdown = Select(title=\"Actual Vs Predicted :\",value='', options=DROPDOWN_OPTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup table\n",
    "table_source = ColumnDataSource(dict(data))\n",
    "#COLUMNS = ['text','tokens','airline_sentiment','predictions','negative','neutral','positive']\n",
    "table_columns = [TableColumn(field=col, title=col) for col in ['text']]\n",
    "data_table = DataTable(source=table_source, columns=table_columns, width=800, height=280,css_classes=[\"my_table\"])\n",
    "\n",
    "table_style = Div(text=\"\"\"\n",
    "<style>\n",
    ".my_table{\n",
    "font-weight:bold !important;\n",
    "border-collapse: collapse;\n",
    "width: 100%;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "#show(row(data_table,table_style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    }
   ],
   "source": [
    "#set up donut plot\n",
    "donut_source = ColumnDataSource(dict(target_prob=[],probability_score=[],angle=[],color=[]))\n",
    "donut_chart = figure(plot_height=300, plot_width=400,title=\"Probability\", toolbar_location=None,\n",
    "        tools=\"hover\", tooltips=\"@target_prob: @probability_score\",x_range=(-.5, .5))\n",
    "donut_chart.annular_wedge(x=0, y=1, inner_radius=0.15, outer_radius=0.25,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", fill_color='color', legend='target_prob', source=donut_source)\n",
    "donut_chart.axis.axis_label=None\n",
    "donut_chart.axis.visible=False\n",
    "donut_chart.grid.grid_line_color = None\n",
    "#show(donut_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup top kewords\n",
    "tfidf['normalize_tfidf']=(tfidf['tfidf']-tfidf['tfidf'].min())/(tfidf['tfidf'].max()-tfidf['tfidf'].min())\n",
    "tfidf_dict = pd.Series(tfidf.normalize_tfidf.values,index=tfidf.token).to_dict()\n",
    "tokens_source= ColumnDataSource(dict(tokens=[],weight=[],color=[]))\n",
    "\n",
    "#tokens = ['aa', 'bad', 'good', 'beaty', 'carry', 'adb']\n",
    "# years = [.40, .20, .31,.62,.45,.81]\n",
    "\n",
    "# dummy_data = {'tokens' : tokens,\n",
    "#         'years'   : years,\n",
    "#         'color' :Category20[len(tokens)]\n",
    "#         }\n",
    "\n",
    "# dummy_source = ColumnDataSource(dummy_data)\n",
    "#import random\n",
    "#tokens_source.data['tokens']=['usairways', 'i', 'can', 'legitimately', 'say', 'that', 'iii', 'would', 'have', 'rather', 'driven', 'cross', 'country', 'than', 'flown', 'on', 'us', 'airways']\n",
    "#tokens_source.data['weight']=[random.uniform(0,1) for i in range(18)]\n",
    "#tokens_source.data['color']=Category20[18]\n",
    "hbar_plot = figure(y_range=tokens_source.data['tokens'], x_range=(0, 1), plot_width=400,plot_height=300 ,title=\"Top Weighted tokens\",\n",
    "           toolbar_location=None, tooltips=\"@tokens: @weight\")\n",
    "\n",
    "hbar_plot.hbar(y='tokens', right='weight', height=0.8, source=tokens_source,\n",
    "       color='color')\n",
    "hbar_plot.grid.grid_line_color = None\n",
    "#show(hbar_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up callbacks\n",
    "dropdown_on_change_update = \"\"\"\n",
    "        var actual_val = (dropdown.value).split(\" \")[2];\n",
    "        var predict_val = (dropdown.value).split(\" \")[6];\n",
    "        table_source.data = source.data;\n",
    "        var update_data = table_source.data;\n",
    "        var data = update_data;\n",
    "        update_data = {};\n",
    "        \n",
    "        //Change in the table\n",
    "        var column = Object.keys(data);\n",
    "        for (var i=0;i<column.length;i++){\n",
    "            update_data[column[i]]=[];\n",
    "\n",
    "        }\n",
    "        for(var i=0 ; i<data['airline_sentiment'].length;i++){\n",
    "                if (data['airline_sentiment'][i] == actual_val && data['predictions'][i]== predict_val){\n",
    "                    for (var j=0; j<column.length;j++){\n",
    "                        var value = data[column[j]][i];\n",
    "                        update_data[column[j]].push(value);\n",
    "\n",
    "                    }\n",
    "\n",
    "                }\n",
    "\n",
    "        }\n",
    "\n",
    "        table_source.data = update_data;\n",
    "        \n",
    "        //Change in donut chart\n",
    "        update_data = donut_source.data;\n",
    "        update_data['target_prob'] = CLASS_NAME;\n",
    "        update_data['probability_score'] = [table_source.data[CATEGORY_DICT[0]][0],table_source.data[CATEGORY_DICT[1]][0],table_source.data[CATEGORY_DICT[2]][0]];\n",
    "        var angle1 = update_data['probability_score'][0]/1*2*3.141592653589793;\n",
    "        var angle2 = update_data['probability_score'][1]/1*2*3.141592653589793;\n",
    "        var angle3 = update_data['probability_score'][2]/1*2*3.141592653589793;\n",
    "        update_data['angle'] = [angle1,angle2,angle3];\n",
    "        update_data['color'] = ['#1f77b4', '#ff7f0e', '#2ca02c'];\n",
    "    \n",
    "        donut_source.data = update_data;\n",
    "        //donut_source.data = {};\n",
    "        //tokens_source.data = {};\n",
    "        donut_source.change.emit();\n",
    "        //tokens_source.change.emit();\n",
    "        table_source.change.emit();\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "callback_1 = CustomJS(args=dict(table_source=table_source,donut_source=donut_source,tokens_source=tokens_source,source=source,dropdown=dropdown,CLASS_NAME=CLASS_NAME,CATEGORY_DICT=CATEGORY_DICT,),code=dropdown_on_change_update)\n",
    "dropdown.js_on_change('value',callback_1)\n",
    "\n",
    "\n",
    "\n",
    "table_on_change_update = \"\"\"\n",
    "            var data = table_source.data;\n",
    "            var ind = cb_obj.indices;\n",
    "            var p_c = donut_source.data;\n",
    "            p_c['target_prob'] = CLASS_NAME;\n",
    "            p_c['color'] = ['#1f77b4', '#ff7f0e', '#2ca02c'];\n",
    "            var sum_prob=1;\n",
    "            for (var i = 0; i < 3; i++){\n",
    "                p_c['probability_score'][0] = data[CATEGORY_DICT[0]][ind];\n",
    "                p_c['probability_score'][1] = data[CATEGORY_DICT[1]][ind];\n",
    "                p_c['probability_score'][2] = data[CATEGORY_DICT[2]][ind];\n",
    "                p_c['angle'][0]= p_c['probability_score'][0]/sum_prob*2*3.141592653589793;\n",
    "                p_c['angle'][1]= p_c['probability_score'][1]/sum_prob*2*3.141592653589793;\n",
    "                p_c['angle'][2]= p_c['probability_score'][2]/sum_prob*2*3.141592653589793;\n",
    "\n",
    "            }\n",
    "            donut_source.data = p_c;\n",
    "            donut_source.change.emit();\n",
    "            \n",
    "            //tokens_source.data={};\n",
    "            //tokens_source.data['weight']=[];\n",
    "            //tokens_source.data['color']=[];\n",
    "            var temp_dict={};\n",
    "            var tokens = table_source.data['tokens'][ind];\n",
    "            tokens = tokens.slice(1,-1);\n",
    "            tokens = tokens.split(',');\n",
    "            console.log(tokens);\n",
    "            for (var t =0 ;t< tokens.length;t++){\n",
    "                var key = tokens[t].trim().slice(1,-1);\n",
    "                //console.log(key);\n",
    "                //console.log(key in tfidf_dict);\n",
    "                if (key in tfidf_dict){\n",
    "                  temp_dict[key]=tfidf_dict[key];\n",
    "                }\n",
    "            }\n",
    "            console.log(temp_dict);\n",
    "            function sortOnKeys(dict,N_TOP) {\n",
    "\n",
    "                var sorted = [];;\n",
    "                var reverse_dict = {}\n",
    "                for (var key in dict){\n",
    "                    reverse_dict[dict[key]]=key;\n",
    "                }\n",
    "                for(var key in reverse_dict){\n",
    "                    sorted[sorted.length] = key;\n",
    "                }\n",
    "                sorted = sorted.sort().reverse();\n",
    "                \n",
    "                //console.log(sorted);\n",
    "                var tempDict = {};\n",
    "                var tokens =[];\n",
    "                var weight = [];\n",
    "                for(var i = 0; i < sorted.length; i++) {\n",
    "                    if (N_TOP >= i){\n",
    "                        tempDict[reverse_dict[sorted[i]]] = parseFloat(sorted[i]);\n",
    "                        //tokens.push(reverse_dict[sorted[i]]);\n",
    "                        //weight.push(parseFloat(sorted[i]));\n",
    "                    }\n",
    "                }\n",
    "                for (key in dict){\n",
    "                    if (key in tempDict){\n",
    "                        tokens.push(key);\n",
    "                        weight.push(parseFloat(dict[key]));\n",
    "                    }\n",
    "                \n",
    "                }\n",
    "                var result=[];\n",
    "                result.push(tempDict);\n",
    "                result.push(tokens);\n",
    "                result.push(weight);\n",
    "                return result;\n",
    "            }\n",
    "            var result = sortOnKeys(temp_dict,N_TOP);\n",
    "            var update_token_source={};\n",
    "            update_token_source['tokens'] = result[1];\n",
    "            update_token_source['weight']=result[2];\n",
    "            update_token_source['color']=COLOR_CODE_LIST.slice(0,[update_token_source['tokens'].length]);\n",
    "            console.log(update_token_source);\n",
    "            \n",
    "            tokens_source.data=update_token_source;\n",
    "            hbar_plot.y_range.factors=update_token_source['tokens'];\n",
    "            console.log(tokens_source.data);\n",
    "            tokens_source.change.emit();\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "callback_2 = CustomJS(args=dict(table_source=table_source,donut_source=donut_source,CATEGORY_DICT=CATEGORY_DICT,CLASS_NAME=CLASS_NAME,tfidf_dict=tfidf_dict,tokens_source=tokens_source,N_TOP=N_TOP,hbar_plot=hbar_plot,COLOR_CODE_LIST=COLOR_CODE_LIST),code=table_on_change_update)\n",
    "table_source.selected.js_on_change('indices', callback_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_layout = row(hbar_plot,donut_chart)\n",
    "dashboard_layout = column(data_table,dashboard_layout,table_style)\n",
    "\n",
    "control_summary = column(dropdown,heatmap,classification_report_summary,classification_report)\n",
    "\n",
    "#layout = row(control_summary,dashboard_layout,sizing_mode='scale_width')\n",
    "layout = row(control_summary,dashboard_layout)\n",
    "\n",
    "final_layout = column(header,layout)\n",
    "\n",
    "curdoc().add_root(final_layout)\n",
    "#show(final_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(\"layout.html\")\n",
    "show(final_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
